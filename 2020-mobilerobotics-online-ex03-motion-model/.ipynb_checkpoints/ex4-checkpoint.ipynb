{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "\n",
    "**_DISCLAIMER:_** The notation used in this exercise follows the one of the Probabilistic Robotics book (refer to Chapter 5.4 in case you have doubts).\n",
    "\n",
    "## 4.1 Inverse motion model\n",
    "\n",
    "The odometry model uses the _relative motion information_. The odometry readings are $u_t = [{\\overline{x}}_{t-1} , {\\overline{x}}_{t}]$, where $\\overline{x}_{t-1}$ and  $\\overline{x}_t$ are poses in a robot-internal coordinate frame (different from the map).\n",
    "\n",
    "The function `inverse_motion_model` takes as input an odometry reading $u_t$ that consist in:\n",
    "\n",
    "- the initial pose of the robot in the odometry coordinate frame $\\overline{x}_{t-1} = [\\overline{x},\\overline{y},\\overline{\\theta}]$\n",
    "- the estimated pose of the robot in the odometry coordinate frame $\\overline{x}_t = [\\overline{x}',\\overline{y}',\\overline{\\theta}']$\n",
    "\n",
    "The output is the relative motion $\\delta_{rot1}, \\delta_{trans}, \\delta_{rot2}$.\n",
    "\n",
    "Implement the function `inverse_motion_model` and verify that it is correct for some test input. **[2.0]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Odometry-based motion model\n",
    "\n",
    "The function `motion_model_odometry` computes the posterior $p(x_t | u_t, x_{t-1})$ from odometry readings.\n",
    "\n",
    "This function takes as input:\n",
    "\n",
    "- the initial pose of the robot $x_{t-1} = [x,y,\\theta]$ _(**map** coordinate frame)_\n",
    "- the hypothesized (or query) final pose $x_{t} = [x', y', \\theta']$ _(**map** coordinate frame)_\n",
    "- the odometry readings $u_t = [\\overline{x}_{t-1} \\overline{x}_t]$ _(**odometry** coordinate frame)_\n",
    "- the noise parameters $\\mathbf{\\alpha} = [\\alpha_1, \\alpha_2, \\alpha_3, \\alpha_4]$\n",
    "\n",
    "The output is the probability $p(x_t | u_t, x_{t-1})$\n",
    "\n",
    "Assume that a robot starts at pose $x_0 = [2.0, 3.0, 0.0]$ in the map frame and moves according to a motion model with $\\mathbf{\\alpha} = [1.0, 1.0, 0.01, 0.01]$.\n",
    "\n",
    "The robot excecutes one motion command and the odometry readings are:\n",
    "\n",
    "1. $\\overline{x}_0 = [0.0 , 0.0 , 0.0   ]$\n",
    "2. $\\overline{x}_1 = [0.5 , 0.0 , \\pi/2 ]$\n",
    "\n",
    "Implement the `motion_model_odometry` function and verify that it is correct for some test input. **[1.0]**\n",
    "\n",
    "---\n",
    "\n",
    "Consider a 150x150 grid map the world with a resolution of 0.01, centered in the original position of the robot.\n",
    "\n",
    "Plot the posterior $p(x_t | u_t, x_{t-1})$ for all possible $[x, y]$ values from the grid. **[2.0]**\n",
    "\n",
    "**Note that** the query input is a position, not a pose. Therefore, to plot the posterior belief over the gridmap, you can assume the term $\\hat{\\delta}_\\mathrm{rot2}$ to be zero and, for each position, integrate over all possible orientations. This can be implemented by considering $p_3 = 1.0$ in the equations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Sample odometry motion model\n",
    "\n",
    "The `motion_model_odometry` requires high computation complexity and does not scale well to large real-world environments. \n",
    "\n",
    "One effective approach to approximate $p(x_t | u_t, x_{t-1})$ is to use **sampling**.\n",
    "\n",
    "The `sample_motion_model_odometry` function defines the sampling-based odometry motion model. \n",
    "\n",
    "This function takes as input:\n",
    "\n",
    "- the initial pose of the robot $x_{t-1} = [x,y,\\theta]$ _(**map** coordinate frame)_\n",
    "- the odometry readings $u_t = [\\overline{x}_{t-1} \\overline{x}_t]$ _(**odometry** coordinate frame)_\n",
    "- the noise parameters $\\mathbf{\\alpha} = [\\alpha_1, \\alpha_2, \\alpha_3, \\alpha_4]$\n",
    "\n",
    "The output is a new (sampled) pose predicted by the motion model.\n",
    "\n",
    "Implement the `sample_motion_model_odometry` function and verify that it is correct for some test input. **[2.0]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Evaluate sample odometry motion model\n",
    "\n",
    "Assume that a robot starts at pose $x_0 = [2.0, 3.0, 0.0]$ in the map frame and moves according to a motion model with $\\mathbf{\\alpha} = [0.1, 0.1, 0.01, 0.01]$.\n",
    "\n",
    "The robot obtains the following odometry readings:\n",
    "\n",
    "1. $\\overline{x}_0 = [0.0 , 0.0 , 0.0   ]$\n",
    "2. $\\overline{x}_1 = [0.5 , 0.0 , \\pi/2 ]$\n",
    "3. $\\overline{x}_2 = [0.5 , 0.5 , 0.0   ]$\n",
    "4. $\\overline{x}_3 = [1.0 , 0.5 , 0.0   ]$\n",
    "5. $\\overline{x}_4 = [1.0 , 1.5 , \\pi/2 ]$\n",
    "6. $\\overline{x}_5 = [1.0 , 2.5 , \\pi/2 ]$\n",
    "\n",
    "Evaluate the `sample_motion_model_odometry` by considering 1000 samples and plot the resulting positions for each sample in one unique plot. **[3.0]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
